{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443bfdf1",
   "metadata": {},
   "source": [
    "\n",
    "# Lab: Detecção de Anomalias Offshore (SGD Online) + **Produtor MQTT**\n",
    "### (atualizado: *event timestamp* baseado em `t_mid` + **produtor_unix_ts**)\n",
    "\n",
    "Este notebook simula sinais estruturais de uma coluna de plataforma offshore, extrai features\n",
    "em janelas deslizantes, treina **modelos rasos** via **SGD online** e publica mensagens **MQTT**.\n",
    "Atualizações:\n",
    "\n",
    "- Incluído **carimbo de tempo do evento** (`event_unix_ts`) derivado de `t_mid`.\n",
    "- Incluído **carimbo de tempo do produtor** (`producer_unix_ts`) no momento do `publish`.\n",
    "- Célula extra de **latência de detecção** (com base no dano simulado).\n",
    "- Bloco de **instruções** para configurar o *bridge* (MQTT→InfluxDB) a usar `event_unix_ts` como `time`.\n",
    "\n",
    "> Em produção, o *event timestamp* deve vir do domínio do sinal/medição; aqui usamos `t_mid` (centro da janela).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa092a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Requisitos (execute uma vez, se necessário)\n",
    "# !pip install paho-mqtt --quiet\n",
    "# !pip install torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, json, time\n",
    "from scipy.signal import welch, stft\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "try:\n",
    "    import paho.mqtt.client as mqtt\n",
    "    HAS_MQTT = True\n",
    "except Exception as e:\n",
    "    print(\"paho-mqtt não disponível:\", e)\n",
    "    HAS_MQTT = False\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Versões -> numpy\", np.__version__, \"| pandas\", pd.__version__, \"| torch\", torch.__version__)\n",
    "print(\"MQTT disponível?\", HAS_MQTT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff5347",
   "metadata": {},
   "source": [
    "## Simulador (SDOF) com injeção de dano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_sdof(T=1800, fs=200, m=1.0, c=0.02, k=1000.0, damage_t=900, delta=0.02,\n",
    "                  sea_noise_level=0.1, accel_noise_level=0.02):\n",
    "    n = int(T*fs)\n",
    "    dt = 1.0/fs\n",
    "    x = np.zeros(n); v = np.zeros(n); a = np.zeros(n)\n",
    "    k_t = k\n",
    "    forcing = sea_noise_level*np.random.randn(n) + 0.02*np.sin(np.linspace(0, 40*math.pi, n))\n",
    "    strain = np.zeros(n)\n",
    "    is_damaged = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(1,n):\n",
    "        if i == int(damage_t*fs):\n",
    "            k_t = k*(1.0-delta)\n",
    "        if i >= int(damage_t*fs):\n",
    "            is_damaged[i] = 1\n",
    "        a[i] = (forcing[i] - c*v[i-1] - k_t*x[i-1]) / m\n",
    "        v[i] = v[i-1] + a[i]*dt\n",
    "        x[i] = x[i-1] + v[i]*dt\n",
    "        strain[i] = x[i] * k_t\n",
    "\n",
    "    accel = a + accel_noise_level*np.random.randn(n)\n",
    "    temp = 20 + 5*np.sin(np.linspace(0, 6*math.pi, n)) + 0.2*np.random.randn(n)\n",
    "    wind = 5 + 2*np.sin(np.linspace(0, 10*math.pi, n)) + 0.5*np.random.randn(n)\n",
    "    return accel, strain, temp, wind, fs, is_damaged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad051e8",
   "metadata": {},
   "source": [
    "## Extração de features (f₁ via Welch, RMS, tendências)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_f1(accel_win, fs, fmin=0.1, fmax=50.0):\n",
    "    f, Pxx = welch(accel_win, fs=fs, nperseg=min(len(accel_win)//2, 512))\n",
    "    mask = (f >= fmin) & (f <= fmax)\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    f_slice = f[mask]\n",
    "    P_slice = Pxx[mask]\n",
    "    idx = np.argmax(P_slice)\n",
    "    return float(f_slice[idx])\n",
    "\n",
    "def extract_features(accel_win, strain_win, temp_win, wind_win, fs):\n",
    "    f1 = estimate_f1(accel_win, fs)\n",
    "    rms = float(np.sqrt(np.mean(accel_win**2)))\n",
    "    x_idx = np.arange(len(strain_win), dtype=float)\n",
    "    st_mean = float(np.mean(strain_win))\n",
    "    st_slope = float(np.polyfit(x_idx, strain_win, 1)[0]) if len(strain_win) > 1 else 0.0\n",
    "    t_mean = float(np.mean(temp_win))\n",
    "    w_mean = float(np.mean(wind_win))\n",
    "    return np.array([f1, rms, st_mean, st_slope, t_mean, w_mean], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0181d59",
   "metadata": {},
   "source": [
    "## Modelos rasos (baseline linear + autoencoder) com **SGD online**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearBaseline(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(d, 1, bias=False)\n",
    "        nn.init.zeros_(self.lin.weight)\n",
    "    def forward(self, u):\n",
    "        return self.lin(u).squeeze(-1)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, d_in=5, h1=16, z=8):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(d_in, h1), nn.ReLU(), nn.Linear(h1, z))\n",
    "        self.dec = nn.Sequential(nn.Linear(z, h1), nn.ReLU(), nn.Linear(h1, d_in))\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        return self.dec(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4311d2e",
   "metadata": {},
   "source": [
    "## Configuração MQTT + **timestamps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuração MQTT\n",
    "MQTT_BROKER = \"localhost\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_KEEPALIVE = 60\n",
    "MQTT_TOPIC_ANOM = \"plataforma/anomalia\"\n",
    "\n",
    "mqtt_client = None\n",
    "if 'mqtt' in globals() and HAS_MQTT:\n",
    "    try:\n",
    "        mqtt_client = mqtt.Client()\n",
    "        mqtt_client.connect(MQTT_BROKER, MQTT_PORT, MQTT_KEEPALIVE)\n",
    "        print(f\"Conectado ao broker MQTT {MQTT_BROKER}:{MQTT_PORT}\")\n",
    "    except Exception as e:\n",
    "        print(\"Falha ao conectar no broker MQTT:\", e)\n",
    "else:\n",
    "    print(\"paho-mqtt indisponível; a publicação MQTT será ignorada.\")\n",
    "\n",
    "# Base temporal para converter t_mid (s) em epoch\n",
    "BASE_EVENT_UNIX_TS = time.time()\n",
    "print(\"BASE_EVENT_UNIX_TS =\", BASE_EVENT_UNIX_TS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a6c12",
   "metadata": {},
   "source": [
    "## Loop online: janelas, SGD, **publicação MQTT** com `event_unix_ts` e `producer_unix_ts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parâmetros\n",
    "T = 1800\n",
    "fs = 200\n",
    "win_sec = 4.0\n",
    "overlap = 0.5\n",
    "win = int(win_sec*fs)\n",
    "step = int(win*(1.0-overlap))\n",
    "\n",
    "accel, strain, temp, wind, fs, is_damaged = simulate_sdof(T=T, fs=fs, damage_t=900, delta=0.02)\n",
    "\n",
    "# Modelos\n",
    "d_u = 6  # 5 features + 1 bias\n",
    "baseline = LinearBaseline(d=d_u)\n",
    "opt_lin = optim.SGD(baseline.parameters(), lr=1e-3)\n",
    "ae = AE(d_in=5, h1=16, z=8)\n",
    "opt_ae = optim.SGD(ae.parameters(), lr=1e-3)\n",
    "\n",
    "hist = []\n",
    "scores_hist = []\n",
    "\n",
    "def publish_mqtt(payload: dict):\n",
    "    if mqtt_client is None:\n",
    "        return\n",
    "    try:\n",
    "        mqtt_client.publish(MQTT_TOPIC_ANOM, json.dumps(payload))\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao publicar MQTT:\", e)\n",
    "\n",
    "for start in range(0, len(accel)-win, step):\n",
    "    sl = slice(start, start+win)\n",
    "    accw, stw, tw, ww = accel[sl], strain[sl], temp[sl], wind[sl]\n",
    "    feats = extract_features(accw, stw, tw, ww, fs)\n",
    "    f1 = feats[0]\n",
    "    if not np.isfinite(f1):\n",
    "        continue\n",
    "\n",
    "    feats_lin = feats[1:]  # [rms, st_mean, st_slope, t_mean, w_mean]\n",
    "    u = np.r_[feats_lin, 1.0].astype(np.float32)\n",
    "    u_t = torch.from_numpy(u).unsqueeze(0)\n",
    "    y_t = torch.tensor([f1], dtype=torch.float32)\n",
    "\n",
    "    # Baseline linear (SGD)\n",
    "    opt_lin.zero_grad()\n",
    "    y_hat = baseline(u_t)\n",
    "    loss_lin = (y_hat - y_t).pow(2).mean()\n",
    "    loss_lin.backward()\n",
    "    opt_lin.step()\n",
    "\n",
    "    # Autoencoder (SGD)\n",
    "    x_in = torch.from_numpy(feats_lin).unsqueeze(0)\n",
    "    opt_ae.zero_grad()\n",
    "    x_rec = ae(x_in)\n",
    "    loss_ae = ((x_rec - x_in)**2).mean()\n",
    "    loss_ae.backward()\n",
    "    opt_ae.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat_detached = baseline(u_t).item()\n",
    "        score_pred = abs(f1 - y_hat_detached)\n",
    "        score_rec = float(loss_ae.item())\n",
    "        score = score_pred + score_rec\n",
    "        scores_hist.append(score)\n",
    "        thr = float(np.quantile(scores_hist[-120:], 0.99)) if len(scores_hist) > 120 else float(\"inf\")\n",
    "        alert = bool(score > thr)\n",
    "\n",
    "    t_mid = (start + win//2) / fs                               # segundos desde o início da simulação\n",
    "    event_unix_ts = BASE_EVENT_UNIX_TS + t_mid                  # timestamp do evento (centro da janela)\n",
    "    producer_unix_ts = time.time()                              # timestamp do produtor no publish\n",
    "\n",
    "    damaged = int(np.any(is_damaged[sl]))\n",
    "\n",
    "    row = dict(t=t_mid, event_unix_ts=event_unix_ts, producer_unix_ts=producer_unix_ts,\n",
    "               f1_obs=float(f1), f1_pred=float(y_hat_detached), \n",
    "               loss_ae=float(loss_ae.item()), score=float(score), thr=float(thr),\n",
    "               alert=alert, damaged=damaged)\n",
    "    hist.append(row)\n",
    "\n",
    "    publish_mqtt({\n",
    "        \"event_unix_ts\": event_unix_ts,\n",
    "        \"producer_unix_ts\": producer_unix_ts,\n",
    "        \"t_mid\": t_mid,\n",
    "        \"f1_obs\": float(f1),\n",
    "        \"f1_pred\": float(y_hat_detached),\n",
    "        \"score\": float(score),\n",
    "        \"threshold\": float(thr),\n",
    "        \"alert\": alert,\n",
    "        \"damaged\": damaged\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(hist)\n",
    "print(\"Janelas processadas:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829abef",
   "metadata": {},
   "source": [
    "## Visualizações (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c014042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['f1_obs'], label='f1_obs')\n",
    "plt.plot(df['t'], df['f1_pred'], label='f1_pred')\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('f1 (Hz)')\n",
    "plt.title('f1 observado vs previsto')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['score'], label='score')\n",
    "plt.plot(df['t'], df['thr'], label='threshold')\n",
    "if df['damaged'].any():\n",
    "    t_damage_start = df.loc[df['damaged']==1, 't'].min()\n",
    "    plt.axvspan(t_damage_start, df['t'].max(), alpha=0.2)\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score e limiar adaptativo')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a49cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['alert'].astype(int), drawstyle='steps-post')\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Alerta (0/1)')\n",
    "plt.title('Alertas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5898546",
   "metadata": {},
   "source": [
    "## Visualização 3D (espectrograma STFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a968b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T_demo = 60\n",
    "fs_demo = 200\n",
    "def simulate_for_3d(T=60, fs=200, damage_t=30.0, delta=0.03):\n",
    "    accel, _, _, _, _, _ = simulate_sdof(T=T, fs=fs, damage_t=damage_t, delta=delta)\n",
    "    return accel\n",
    "\n",
    "accel_demo = simulate_for_3d(T=T_demo, fs=fs_demo, damage_t=30, delta=0.03)\n",
    "f, tt, Zxx = stft(accel_demo, fs=fs_demo, nperseg=256, noverlap=128)\n",
    "S = np.abs(Zxx)\n",
    "mask = f <= 40\n",
    "f_plot = f[mask]\n",
    "S_plot = S[mask, :]\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "T_mesh, F_mesh = np.meshgrid(tt, f_plot)\n",
    "ax.plot_surface(T_mesh, F_mesh, S_plot, linewidth=0, antialiased=True)\n",
    "ax.set_xlabel('Tempo (s)')\n",
    "ax.set_ylabel('Frequência (Hz)')\n",
    "ax.set_zlabel('|STFT|')\n",
    "ax.set_title('Espectrograma 3D (queda de rigidez aos 30s)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259462cb",
   "metadata": {},
   "source": [
    "## Métricas de desempenho + **latência de detecção**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8af5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "det_delay = np.nan\n",
    "first_alert_ts = np.nan\n",
    "first_alert_event_ts = np.nan\n",
    "\n",
    "if df['damaged'].any() and df['alert'].any():\n",
    "    t_damage = df.loc[df['damaged']==1, 't'].min()\n",
    "    after = df[df['t'] >= t_damage]\n",
    "    fired = after[after['alert'] == True]\n",
    "    if len(fired) > 0:\n",
    "        first_alert_t = float(fired['t'].iloc[0])\n",
    "        det_delay = first_alert_t - float(t_damage)\n",
    "        first_row = fired.iloc[0]\n",
    "        first_alert_ts = float(first_row['producer_unix_ts'])\n",
    "        first_alert_event_ts = float(first_row['event_unix_ts'])\n",
    "\n",
    "pre = df[df['damaged']==0]\n",
    "fpr_per_hour = np.nan\n",
    "if len(pre) > 0:\n",
    "    time_pre = pre['t'].max() - pre['t'].min()\n",
    "    alerts_pre = int(pre['alert'].sum())\n",
    "    if time_pre > 0:\n",
    "        fpr_per_hour = float(alerts_pre / (time_pre/3600.0))\n",
    "\n",
    "print(\"Atraso de detecção (s) (evento→primeiro alerta):\", det_delay)\n",
    "print(\"Falsos positivos por hora (aprox):\", fpr_per_hour)\n",
    "print(\"first_alert_event_ts:\", first_alert_event_ts, \"| first_alert_producer_ts:\", first_alert_ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f162a80",
   "metadata": {},
   "source": [
    "## (Opcional) Exportar histórico para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"historico_anomalias.csv\", index=False)\n",
    "print(\"Arquivo salvo: historico_anomalias.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b076d00",
   "metadata": {},
   "source": [
    "\n",
    "## Instruções para o *bridge* MQTT→InfluxDB (usar `event_unix_ts`)\n",
    "No seu *bridge* (Python/InfluxDB client), mapeie:\n",
    "- `time` (timestamp da medição) = `event_unix_ts` (segundos POSIX)\n",
    "- `field`/`tags`: mantenha `producer_unix_ts` como *campo* para calcular **latência de publicação** (`producer_unix_ts - event_unix_ts`).\n",
    "\n",
    "Em cenários reais, se o produtor souber o instante preciso da janela (ex.: *hardware timestamp*), substitua `BASE_EVENT_UNIX_TS` pelo tempo absoluto de início da aquisição.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}