{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382ab777",
   "metadata": {},
   "source": [
    "\n",
    "# Lab: Detecção de Anomalias em Colunas de Plataformas Offshore (Tempo Quase Real, SGD Online)\n",
    "\n",
    "Este laboratório cria um pipeline **reprodutível** para simular sinais de uma estrutura offshore,\n",
    "extrair **features** em janelas deslizantes e detectar **anomalias** com modelos rasos atualizados\n",
    "**online** via *Stochastic Gradient Descent (SGD)*.\n",
    "\n",
    "**Componentes principais**:\n",
    "- Simulador SDOF/2DOF com injeção de dano (queda de rigidez)\n",
    "- Extração de frequência natural estimada (f₁) via Welch/peak-picking + features básicas\n",
    "- Baseline físico: regressão linear multivariada (SGD) para predizer f₁ dado mar/temperatura/strain\n",
    "- Autoencoder raso (SGD) para reconstrução de features; score = erro de reconstrução\n",
    "- Fusão de scores + *threshold* adaptativo por quantil móvel\n",
    "- Métricas: atraso de detecção, FPR, (opcional) ROC em cenários simulados\n",
    "- Visualização com **matplotlib** (sem seaborn)\n",
    "\n",
    "> Observação: GD (gradiente descendente) é **método de treino**, não a detecção em si.\n",
    "> A detecção é feita comparando **observado vs. previsto/reconstruído**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup & imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import welch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Para reproducibilidade (pode variar intencionalmente para testar robustez)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Versões: numpy\", np.__version__, \"| pandas\", pd.__version__, \"| torch\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e56f3",
   "metadata": {},
   "source": [
    "## Simulador SDOF com injeção de dano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d43a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_sdof(T=1800, fs=200, m=1.0, c=0.02, k=1000.0, damage_t=900, delta=0.02,\n",
    "                   sea_noise_level=0.1, accel_noise_level=0.02):\n",
    "    \"\"\"\n",
    "    Simula um SDOF excitado por ruído (mar) e injeta dano como queda de rigidez.\n",
    "    Retorna: aceleração, strain (proxy), temperatura, vento, fs, vetor de rótulos 'is_damaged' (0/1).\n",
    "    \"\"\"\n",
    "    n = T*fs\n",
    "    dt = 1.0/fs\n",
    "    x = np.zeros(n); v = np.zeros(n); a = np.zeros(n)\n",
    "    k_t = k\n",
    "    # Forcing pseudo-mar: ruído branco suavizado + componente baixa-freq\n",
    "    forcing = sea_noise_level*np.random.randn(n) + 0.02*np.sin(np.linspace(0, 40*math.pi, n))\n",
    "    strain = np.zeros(n)\n",
    "    is_damaged = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(1,n):\n",
    "        if i == int(damage_t*fs):\n",
    "            k_t = k*(1.0-delta)\n",
    "        if i >= int(damage_t*fs):\n",
    "            is_damaged[i] = 1\n",
    "        a[i] = (forcing[i] - c*v[i-1] - k_t*x[i-1]) / m\n",
    "        v[i] = v[i-1] + a[i]*dt\n",
    "        x[i] = x[i-1] + v[i]*dt\n",
    "        # Strain proxy proporcional a deslocamento * rigidez instantânea (simplificação)\n",
    "        strain[i] = x[i] * k_t\n",
    "\n",
    "    accel = a + accel_noise_level*np.random.randn(n)\n",
    "    # Temperatura e vento como covariáveis lentas\n",
    "    temp = 20 + 5*np.sin(np.linspace(0, 6*math.pi, n)) + 0.2*np.random.randn(n)\n",
    "    wind = 5 + 2*np.sin(np.linspace(0, 10*math.pi, n)) + 0.5*np.random.randn(n)\n",
    "    return accel, strain, temp, wind, fs, is_damaged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b8eb3",
   "metadata": {},
   "source": [
    "## Extração de features por janelas (f₁ via Welch, RMS, tendências)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_f1(accel_win, fs, fmin=0.1, fmax=50.0):\n",
    "    f, Pxx = welch(accel_win, fs=fs, nperseg=min(len(accel_win)//2, 512))\n",
    "    mask = (f >= fmin) & (f <= fmax)\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    f_slice = f[mask]\n",
    "    P_slice = Pxx[mask]\n",
    "    idx = np.argmax(P_slice)\n",
    "    return float(f_slice[idx])\n",
    "\n",
    "def extract_features(accel_win, strain_win, temp_win, wind_win, fs):\n",
    "    f1 = estimate_f1(accel_win, fs)\n",
    "    rms = float(np.sqrt(np.mean(accel_win**2)))\n",
    "    # Tendências lineares simples\n",
    "    x_idx = np.arange(len(strain_win), dtype=float)\n",
    "    st_mean = float(np.mean(strain_win))\n",
    "    st_slope = float(np.polyfit(x_idx, strain_win, 1)[0]) if len(strain_win) > 1 else 0.0\n",
    "    t_mean = float(np.mean(temp_win))\n",
    "    w_mean = float(np.mean(wind_win))\n",
    "    return np.array([f1, rms, st_mean, st_slope, t_mean, w_mean], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4836b9",
   "metadata": {},
   "source": [
    "## Modelos rasos com treino online (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearBaseline(nn.Module):\n",
    "    \"\"\"Prediz f1 a partir de [rms, st_mean, st_slope, t_mean, w_mean, bias].\"\"\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        # Peso único: y_hat = w^T u  (implementado como nn.Linear sem bias explícito)\n",
    "        self.lin = nn.Linear(d, 1, bias=False)\n",
    "        # Inicialização leve\n",
    "        nn.init.zeros_(self.lin.weight)\n",
    "\n",
    "    def forward(self, u):\n",
    "        return self.lin(u).squeeze(-1)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, d_in=5, h1=16, z=8):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(d_in, h1), nn.ReLU(), nn.Linear(h1, z))\n",
    "        self.dec = nn.Sequential(nn.Linear(z, h1), nn.ReLU(), nn.Linear(h1, d_in))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        xrec = self.dec(z)\n",
    "        return xrec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf7eb0",
   "metadata": {},
   "source": [
    "## Loop online: janelas deslizantes, atualização SGD, scores e threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parâmetros de simulação e janelamento\n",
    "T = 1800          # segundos totais\n",
    "fs = 200          # Hz\n",
    "win_sec = 4.0\n",
    "overlap = 0.5\n",
    "win = int(win_sec*fs)\n",
    "step = int(win*(1.0-overlap))\n",
    "\n",
    "accel, strain, temp, wind, fs, is_damaged = simulate_sdof(T=T, fs=fs, damage_t=900, delta=0.02)\n",
    "\n",
    "# Modelos & otimizadores\n",
    "# Baseline linear: entrada = [rms, st_mean, st_slope, t_mean, w_mean, bias]\n",
    "d_u = 6  # 5 features + 1 bias\n",
    "baseline = LinearBaseline(d=d_u)\n",
    "opt_lin = optim.SGD(baseline.parameters(), lr=1e-3)\n",
    "\n",
    "# Autoencoder: entrada = [rms, st_mean, st_slope, t_mean, w_mean]\n",
    "ae = AE(d_in=5, h1=16, z=8)\n",
    "opt_ae = optim.SGD(ae.parameters(), lr=1e-3)\n",
    "\n",
    "hist = []  # iremos guardar dicts com métricas por janela\n",
    "scores_hist = []\n",
    "\n",
    "for start in range(0, len(accel)-win, step):\n",
    "    sl = slice(start, start+win)\n",
    "    accw, stw, tw, ww = accel[sl], strain[sl], temp[sl], wind[sl]\n",
    "    feats = extract_features(accw, stw, tw, ww, fs)\n",
    "    f1 = feats[0]\n",
    "    # Se f1 falhar (nan), pule atualização para esta janela\n",
    "    if not np.isfinite(f1):\n",
    "        continue\n",
    "\n",
    "    # Constrói u para baseline (com bias)\n",
    "    feats_lin = feats[1:]  # [rms, st_mean, st_slope, t_mean, w_mean]\n",
    "    u = np.r_[feats_lin, 1.0].astype(np.float32)\n",
    "    u_t = torch.from_numpy(u).unsqueeze(0)  # (1,6)\n",
    "    y_t = torch.tensor([f1], dtype=torch.float32)  # (1,)\n",
    "\n",
    "    # --- Baseline linear: y_hat ~ f1\n",
    "    opt_lin.zero_grad()\n",
    "    y_hat = baseline(u_t)  # (1,)\n",
    "    loss_lin = (y_hat - y_t).pow(2).mean()\n",
    "    loss_lin.backward()\n",
    "    opt_lin.step()\n",
    "\n",
    "    # --- Autoencoder: reconstruir x_in = feats_lin\n",
    "    x_in = torch.from_numpy(feats_lin).unsqueeze(0)  # (1,5)\n",
    "    opt_ae.zero_grad()\n",
    "    x_rec = ae(x_in)\n",
    "    loss_ae = ((x_rec - x_in)**2).mean()\n",
    "    loss_ae.backward()\n",
    "    opt_ae.step()\n",
    "\n",
    "    # --- Score de anomalia (combinação simples)\n",
    "    with torch.no_grad():\n",
    "        y_hat_detached = baseline(u_t).item()\n",
    "        score_pred = abs(f1 - y_hat_detached)\n",
    "        score_rec = float(loss_ae.item())\n",
    "        score = score_pred + score_rec\n",
    "        scores_hist.append(score)\n",
    "\n",
    "        # threshold adaptativo por quantil móvel (99º), usando ~ 10 min de histórico por padrão\n",
    "        # 10 min de dados => janelas por minuto ~ (60/((win_sec*(1-overlap)))) ; arredondamos para ~120\n",
    "        thr = np.inf\n",
    "        if len(scores_hist) > 120:\n",
    "            thr = float(np.quantile(scores_hist[-120:], 0.99))\n",
    "        alert = (score > thr)\n",
    "\n",
    "    # Marca temporal da janela (segundos)\n",
    "    t_mid = (start + win//2) / fs\n",
    "    damaged = int(np.any(is_damaged[sl]))\n",
    "\n",
    "    hist.append(dict(\n",
    "        t=t_mid, f1_obs=float(f1), f1_pred=float(y_hat_detached), \n",
    "        loss_ae=float(loss_ae.item()), score=float(score), thr=float(thr), \n",
    "        alert=bool(alert), damaged=damaged\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(hist)\n",
    "print(\"Amostras de janelas:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfad5b",
   "metadata": {},
   "source": [
    "## Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 1: f1 observado vs previsto\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['f1_obs'], label='f1_obs')\n",
    "plt.plot(df['t'], df['f1_pred'], label='f1_pred')\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('f1 (Hz)')\n",
    "plt.title('Frequência natural observada vs prevista (baseline linear)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 2: Score vs Threshold + janela de dano\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['score'], label='score')\n",
    "plt.plot(df['t'], df['thr'], label='threshold')\n",
    "# Sombrear região de dano\n",
    "if df['damaged'].any():\n",
    "    t_damage_start = df.loc[df['damaged']==1, 't'].min()\n",
    "    plt.axvspan(t_damage_start, df['t'].max(), alpha=0.2)\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score de anomalia e limiar adaptativo')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 3: Série de alertas (marcadores)\n",
    "plt.figure()\n",
    "plt.plot(df['t'], df['alert'].astype(int), drawstyle='steps-post')\n",
    "plt.xlabel('Tempo (s)')\n",
    "plt.ylabel('Alerta (0/1)')\n",
    "plt.title('Alertas gerados')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1562b8e",
   "metadata": {},
   "source": [
    "## Métricas: atraso de detecção e FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Atraso até 1º alerta após início do dano\n",
    "det_delay = np.nan\n",
    "if df['damaged'].any() and df['alert'].any():\n",
    "    t_damage = df.loc[df['damaged']==1, 't'].min()\n",
    "    after = df[df['t'] >= t_damage]\n",
    "    fired = after[after['alert'] == True]\n",
    "    if len(fired) > 0:\n",
    "        det_delay = float(fired['t'].iloc[0] - t_damage)\n",
    "\n",
    "# FPR: alertas quando 'damaged'==0 dividido por tempo pré-dano\n",
    "pre = df[df['damaged']==0]\n",
    "fpr_per_hour = np.nan\n",
    "if len(pre) > 0:\n",
    "    time_pre = pre['t'].max() - pre['t'].min()\n",
    "    alerts_pre = int(pre['alert'].sum())\n",
    "    if time_pre > 0:\n",
    "        fpr_per_hour = float(alerts_pre / (time_pre/3600.0))\n",
    "\n",
    "print(\"Atraso de detecção (s):\", det_delay)\n",
    "print(\"Falsos positivos por hora (aprox):\", fpr_per_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab3264f",
   "metadata": {},
   "source": [
    "\n",
    "## Extensões sugeridas\n",
    "- **Peak tracking/Kalman** para f₁ reduzir ruído de estimativa\n",
    "- **Quantil condicional**: thresholds por estado de mar/vento\n",
    "- **2DOF/3DOF** no simulador para multi-modos acoplados\n",
    "- **MQTT/Kafka** para streaming real; consumidor executa este loop online\n",
    "- **Banco temporal (InfluxDB/Timescale)** + **Grafana** para dashboard operacional\n",
    "\n",
    "## Suposições e validações\n",
    "- Queda de f₁ pode vir de **temperatura/preload**; o baseline multivariado ajuda a filtrar\n",
    "- AE raso pode **aprender drift**: use janela de treino curta e compare sempre com baseline físico\n",
    "- FFT em janelas curtas: use **Welch/médias**; se necessário, suavize com filtro/trackers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}